{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d3a8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Importando bibliotecas necessárias\n",
    "import spacy\n",
    "from spacy.matcher import Matcher, PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "!python -m spacy download en_core_web_sm\n",
    "# Carregando o modelo\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6780900a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análise detalhada dos tokens:\n",
      "Token  |  Lema  |  POS  |  Tag  |  Dep  |  É Entidade?\n",
      "------------------------------------------------------------\n",
      "In       | in       | ADP    | IN     | prep   | Não\n",
      "2023     | 2023     | NUM    | CD     | pobj   | Sim\n",
      ",        | ,        | PUNCT  | ,      | punct  | Não\n",
      "Apple    | Apple    | PROPN  | NNP    | compound | Sim\n",
      "Inc.     | Inc.     | PROPN  | NNP    | nsubj  | Sim\n",
      "released | release  | VERB   | VBD    | ROOT   | Não\n",
      "its      | its      | PRON   | PRP$   | poss   | Não\n",
      "latest   | late     | ADJ    | JJS    | amod   | Não\n",
      "iPhone   | iPhone   | PROPN  | NNP    | nmod   | Não\n",
      "15       | 15       | NUM    | CD     | nummod | Sim\n",
      "Pro      | pro      | NOUN   | NN     | dobj   | Não\n",
      "for      | for      | ADP    | IN     | prep   | Não\n",
      "$        | $        | SYM    | $      | nmod   | Não\n",
      "999      | 999      | NUM    | CD     | pobj   | Sim\n",
      ".        | .        | PUNCT  | .      | punct  | Não\n",
      "\n",
      "        | \n",
      "        | SPACE  | _SP    | dep    | Não\n",
      "The      | the      | DET    | DT     | det    | Não\n",
      "CEO      | CEO      | PROPN  | NNP    | nsubj  | Não\n",
      ",        | ,        | PUNCT  | ,      | punct  | Não\n",
      "Tim      | Tim      | PROPN  | NNP    | compound | Sim\n",
      "Cook     | Cook     | PROPN  | NNP    | appos  | Sim\n",
      ",        | ,        | PUNCT  | ,      | punct  | Não\n",
      "announced | announce | VERB   | VBD    | ROOT   | Não\n",
      "AI       | AI       | PROPN  | NNP    | compound | Sim\n",
      "features | feature  | NOUN   | NNS    | dobj   | Não\n",
      "that     | that     | PRON   | WDT    | nsubj  | Não\n",
      "will     | will     | AUX    | MD     | aux    | Não\n",
      "revolutionize | revolutionize | VERB   | VB     | relcl  | Não\n",
      "mobile   | mobile   | ADJ    | JJ     | amod   | Não\n",
      "technology | technology | NOUN   | NN     | dobj   | Não\n",
      ".        | .        | PUNCT  | .      | punct  | Não\n",
      "\n",
      "        | \n",
      "        | SPACE  | _SP    | dep    | Não\n",
      "The      | the      | DET    | DT     | det    | Não\n",
      "company  | company  | NOUN   | NN     | poss   | Não\n",
      "'s       | 's       | PART   | POS    | case   | Não\n",
      "stock    | stock    | NOUN   | NN     | nsubj  | Não\n",
      "(        | (        | PUNCT  | -LRB-  | punct  | Não\n",
      "AAPL     | AAPL     | PROPN  | NNP    | appos  | Não\n",
      ")        | )        | PUNCT  | -RRB-  | punct  | Não\n",
      "rose     | rise     | VERB   | VBD    | ROOT   | Não\n",
      "5        | 5        | NUM    | CD     | nummod | Sim\n",
      "%        | %        | NOUN   | NN     | npadvmod | Sim\n",
      "after    | after    | ADP    | IN     | prep   | Não\n",
      "the      | the      | DET    | DT     | det    | Não\n",
      "announcement | announcement | NOUN   | NN     | pobj   | Não\n",
      ".        | .        | PUNCT  | .      | punct  | Não\n",
      "\n",
      "Sentenças identificadas:\n",
      "- In 2023, Apple Inc. released its latest iPhone 15 Pro for $999. \n",
      "\n",
      "- The CEO, Tim Cook, announced AI features that will revolutionize mobile technology.\n",
      "\n",
      "- The company's stock (AAPL) rose 5% after the announcement.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "Criação do texto de exemplo.\n",
    "Processamento dos dados para o objeto que é utilizado no spaCy.\n",
    "Análise detalhada de cada token presente do texto.\n",
    "Todas as sentenças dentro do texto.\n",
    "\"\"\" \n",
    "texto_complexo = \"\"\"In 2023, Apple Inc. released its latest iPhone 15 Pro for $999. \n",
    "The CEO, Tim Cook, announced AI features that will revolutionize mobile technology.\n",
    "The company's stock (AAPL) rose 5% after the announcement.\"\"\"\n",
    "\n",
    "#Instaciação objeto doc\n",
    "doc = nlp(texto_complexo)\n",
    "\n",
    "print(\"Análise detalhada dos tokens:\")\n",
    "print(\"Token  |  Lema  |  POS  |  Tag  |  Dep  |  É Entidade?\")\n",
    "print(\"-\" * 60)\n",
    "for token in doc:\n",
    "    is_ent = \"Sim\" if token.ent_type_ else \"Não\"\n",
    "    print(f\"{token.text:8} | {token.lemma_:8} | {token.pos_:6} | {token.tag_:6} | {token.dep_:6} | {is_ent}\")\n",
    "\n",
    "print(\"\\nSentenças identificadas:\")\n",
    "for sent in doc.sents:\n",
    "    print(f\"- {sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5239f61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entidades encontradas (incluindo customizadas):\n",
      "\n",
      "Texto: 2023\n",
      "Tipo: DATE\n",
      "Explicação: Absolute or relative dates or periods\n",
      "\n",
      "Texto: Apple Inc.\n",
      "Tipo: ORG\n",
      "Explicação: Companies, agencies, institutions, etc.\n",
      "\n",
      "Texto: iPhone 15 Pro\n",
      "Tipo: PRODUTO\n",
      "\n",
      "Texto: 999\n",
      "Tipo: MONEY\n",
      "Explicação: Monetary values, including unit\n",
      "\n",
      "Texto: CEO\n",
      "Tipo: CARGO\n",
      "\n",
      "Texto: Tim Cook\n",
      "Tipo: PERSON\n",
      "Explicação: People, including fictional\n",
      "\n",
      "Texto: AI\n",
      "Tipo: GPE\n",
      "Explicação: Countries, cities, states\n",
      "\n",
      "Texto: AAPL\n",
      "Tipo: TICKER\n",
      "\n",
      "Texto: 5%\n",
      "Tipo: PERCENT\n",
      "Explicação: Percentage, including \"%\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/anaconda3/envs/tf/lib/python3.10/site-packages/spacy/glossary.py:20: UserWarning: [W118] Term 'PRODUTO' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "/home/lucas/anaconda3/envs/tf/lib/python3.10/site-packages/spacy/glossary.py:20: UserWarning: [W118] Term 'CARGO' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "/home/lucas/anaconda3/envs/tf/lib/python3.10/site-packages/spacy/glossary.py:20: UserWarning: [W118] Term 'TICKER' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Criando novos padrões para reconhecer outras entidades.\n",
    "Printando as entidades reconhecidas e a explicação delas.\n",
    "\"\"\"\n",
    "\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "patterns = [\n",
    "    {\"label\": \"PRODUTO\", \"pattern\": \"iPhone 15 Pro\"},\n",
    "    {\"label\": \"TICKER\", \"pattern\": \"AAPL\"},\n",
    "    {\"label\": \"CARGO\", \"pattern\": \"CEO\"}\n",
    "]\n",
    "\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "doc = nlp(texto_complexo)\n",
    "\n",
    "print(\"Entidades encontradas (incluindo customizadas):\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"\\nTexto: {ent.text}\")\n",
    "    print(f\"Tipo: {ent.label_}\")\n",
    "    if spacy.explain(ent.label_):\n",
    "        print(f\"Explicação: {spacy.explain(ent.label_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86c50fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padrões encontrados:\n",
      "Padrão: DATA | Texto: 15 December 2023\n",
      "Padrão: VALOR | Texto: 200 billion\n",
      "Padrão: ACAO | Texto: Microsoft stock\n",
      "Padrão: VALOR | Texto: 180 billion\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Criação de padrões para encontrar o que é desejado.\n",
    "Adicionando esses padrões ao matcher.\n",
    "Demonstração de como funcionou.\n",
    "\"\"\"\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "padrao_monetario = [\n",
    "    {\"LIKE_NUM\": True},\n",
    "    {\"LOWER\": {\"IN\": [\"billion\", \"million\", \"thousand\"]}}\n",
    "]\n",
    "\n",
    "padrao_data = [\n",
    "    {\"LIKE_NUM\": True},\n",
    "    {\"LOWER\": {\"IN\": [\"january\", \"february\", \"march\", \"april\", \"may\", \"june\",\n",
    "                      \"july\", \"august\", \"september\", \"october\", \"november\", \"december\"]}},\n",
    "    {\"LIKE_NUM\": True}\n",
    "]\n",
    "\n",
    "padrao_acao = [\n",
    "    {\"ENT_TYPE\": \"ORG\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},\n",
    "    {\"LOWER\": \"stock\"}\n",
    "]\n",
    "\n",
    "matcher.add(\"VALOR\", [padrao_monetario])\n",
    "matcher.add(\"DATA\", [padrao_data])\n",
    "matcher.add(\"ACAO\", [padrao_acao])\n",
    "\n",
    "texto_teste = \"\"\"On 15 December 2023, Apple's stock reached $200 billion in value. \n",
    "Microsoft stock also performed well, reaching €180 billion.\"\"\"\n",
    "\n",
    "doc = nlp(texto_teste)\n",
    "matches = matcher(doc)\n",
    "\n",
    "print(\"Padrões encontrados:\")\n",
    "for match_id, start, end in matches:\n",
    "    nome_padrao = nlp.vocab.strings[match_id]\n",
    "    texto_encontrado = doc[start:end].text\n",
    "    print(f\"Padrão: {nome_padrao} | Texto: {texto_encontrado}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow (Simples)",
   "language": "python",
   "name": "tf_final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
